{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMI-LSTM Implementation for Peliculas Dataset\n",
    "\n",
    "This notebook contains the implementaion of **EMI-LSTM** for the features extracted from [Peliculas](http://academictorrents.com/details/70e0794e2292fc051a13f05ea6f5b6c16f3d3635/tech&hit=1&filelist=1) dataset.\n",
    "\n",
    "The notebook is an extension of the notebook found in https://github.com/microsoft/EdgeML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----Start------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-19T11:47:35.576928Z",
     "start_time": "2018-08-19T11:47:34.670184Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# To include edgeml in python path\n",
    "sys.path.insert(0, '../../')\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] ='-1'\n",
    "\n",
    "# MI-RNN and EMI-RNN imports\n",
    "from rnn import EMI_DataPipeline\n",
    "from rnn import EMI_BasicLSTM, EMI_GRU, EMI_FastGRNN\n",
    "from emirnnTrainer import EMI_Trainer, EMI_Driver\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us set up some network parameters for the computation graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(dirname):\n",
    "    x_train = np.load(dirname + '/' + 'x_train.npy')\n",
    "    y_train = np.load(dirname + '/' + 'y_train.npy')\n",
    "    x_test = np.load(dirname + '/' + 'x_test.npy')\n",
    "    y_test = np.load(dirname + '/' + 'y_test.npy')\n",
    "    x_val = np.load(dirname + '/' + 'x_val.npy')\n",
    "    y_val = np.load(dirname + '/' + 'y_val.npy')\n",
    "    return x_train, y_train, x_test, y_test, x_val, y_val\n",
    "\n",
    "def bagData(X, Y, subinstanceLen, subinstanceStride):\n",
    "    '''\n",
    "    Takes x and y of shape\n",
    "    [-1, 128, 9] and [-1, 6] respectively and converts it into bags of instances.\n",
    "    returns [-1, numInstance, ]\n",
    "    '''\n",
    "    numClass = 2\n",
    "    numSteps = 24 # Window length\n",
    "    numFeats = 540 # Number of features\n",
    "    assert X.ndim == 3\n",
    "    assert X.shape[1] == numSteps\n",
    "    assert X.shape[2] == numFeats\n",
    "    assert subinstanceLen <= numSteps\n",
    "    assert subinstanceLen > 0 # subinstance length = Number of readings for which the class signature occurs\n",
    "    assert subinstanceStride <= numSteps  \n",
    "    assert subinstanceStride >= 0 \n",
    "    assert len(X) == len(Y)\n",
    "    assert Y.ndim == 2\n",
    "    assert Y.shape[1] == numClass\n",
    "    x_bagged = []\n",
    "    y_bagged = []\n",
    "    for i, point in enumerate(X[:, :, :]):\n",
    "        instanceList = []\n",
    "        start = 0\n",
    "        end = subinstanceLen\n",
    "        while True:\n",
    "            x = point[start:end, :]\n",
    "            if len(x) < subinstanceLen:\n",
    "                x_ = np.zeros([subinstanceLen, x.shape[1]])\n",
    "                x_[:len(x), :] = x[:, :]\n",
    "                x = x_\n",
    "            instanceList.append(x)\n",
    "            if end >= numSteps:\n",
    "                break\n",
    "            start += subinstanceStride\n",
    "            end += subinstanceStride\n",
    "        bag = np.array(instanceList)\n",
    "        numSubinstance = bag.shape[0]\n",
    "        label = Y[i]\n",
    "        label = np.argmax(label)\n",
    "        labelBag = np.zeros([numSubinstance, numClass])\n",
    "        labelBag[:, label] = 1\n",
    "        x_bagged.append(bag)\n",
    "        label = np.array(labelBag)\n",
    "        y_bagged.append(label)\n",
    "    return np.array(x_bagged), np.array(y_bagged)\n",
    "\n",
    "def makeEMIData(subinstanceLen, subinstanceStride, sourceDir, outDir):\n",
    "    x_train, y_train, x_test, y_test, x_val, y_val = loadData(sourceDir)\n",
    "    x, y = bagData(x_train, y_train, subinstanceLen, subinstanceStride)\n",
    "    np.save(outDir + '/x_train.npy', x)\n",
    "    np.save(outDir + '/y_train.npy', y)\n",
    "    print('Num train %d' % len(x))\n",
    "    x, y = bagData(x_test, y_test, subinstanceLen, subinstanceStride)\n",
    "    np.save(outDir + '/x_test.npy', x)\n",
    "    np.save(outDir + '/y_test.npy', y)\n",
    "    print('Num test %d' % len(x))\n",
    "    x, y = bagData(x_val, y_val, subinstanceLen, subinstanceStride)\n",
    "    np.save(outDir + '/x_val.npy', x)\n",
    "    np.save(outDir + '/y_val.npy', y)\n",
    "    print('Num val %d' % len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subinstanceLen = 6\n",
    "subinstanceStride = 2\n",
    "extractedDir = '/home/adithyapa4444_gmail_com'\n",
    "#from os import mkdir\n",
    "# WHEN YOU CHANGE THE ABOVE - CREATE A FOLDER \n",
    "#mkdir('12_3')  \n",
    "rawDir = extractedDir + '/RAW'\n",
    "sourceDir = rawDir\n",
    "outDir = extractedDir + '/%d_%d/' % (subinstanceLen, subinstanceStride)\n",
    "makeEMIData(subinstanceLen, subinstanceStride, sourceDir, outDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EMI-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-19T11:47:35.590781Z",
     "start_time": "2018-08-19T11:47:35.578914Z"
    }
   },
   "outputs": [],
   "source": [
    "def lstm_experiment_generator(params, path = './DSAAR/64_16/'):\n",
    "    \"\"\"\n",
    "        Function that will generate the experiments to be run.\n",
    "        Inputs : \n",
    "        (1) Dictionary params, to set the network parameters.\n",
    "        (2) Name of the Model to be run from [EMI-LSTM, EMI-FastGRNN, EMI-GRU]\n",
    "        (3) Path to the dataset, where the csv files are present.\n",
    "    \"\"\"\n",
    "    \n",
    "    #Copy the contents of the params dictionary.\n",
    "    lstm_dict = {**params}\n",
    "    \n",
    "    #---------------------------PARAM SETTING----------------------#\n",
    "    \n",
    "    # Network parameters for our LSTM + FC Layer\n",
    "    NUM_HIDDEN = params[\"NUM_HIDDEN\"]\n",
    "    NUM_TIMESTEPS = params[\"NUM_TIMESTEPS\"]\n",
    "    ORIGINAL_NUM_TIMESTEPS = params[\"ORIGINAL_NUM_TIMESTEPS\"]\n",
    "    NUM_FEATS = params[\"NUM_FEATS\"]\n",
    "    FORGET_BIAS = params[\"FORGET_BIAS\"]\n",
    "    NUM_OUTPUT = params[\"NUM_OUTPUT\"]\n",
    "    USE_DROPOUT = True if (params[\"USE_DROPOUT\"] == 1) else False\n",
    "    KEEP_PROB = params[\"KEEP_PROB\"]\n",
    "\n",
    "    # For dataset API\n",
    "    PREFETCH_NUM = params[\"PREFETCH_NUM\"]\n",
    "    BATCH_SIZE = params[\"BATCH_SIZE\"]\n",
    "\n",
    "    # Number of epochs in *one iteration*\n",
    "    NUM_EPOCHS = params[\"NUM_EPOCHS\"]\n",
    "    # Number of iterations in *one round*. After each iteration,\n",
    "    # the model is dumped to disk. At the end of the current\n",
    "    # round, the best model among all the dumped models in the\n",
    "    # current round is picked up..\n",
    "    NUM_ITER = params[\"NUM_ITER\"]\n",
    "    # A round consists of multiple training iterations and a belief\n",
    "    # update step using the best model from all of these iterations\n",
    "    NUM_ROUNDS = params[\"NUM_ROUNDS\"]\n",
    "    LEARNING_RATE = params[\"LEARNING_RATE\"]\n",
    "\n",
    "    # A staging direcory to store models\n",
    "    MODEL_PREFIX = params[\"MODEL_PREFIX\"]\n",
    "    \n",
    "    #----------------------END OF PARAM SETTING----------------------#\n",
    "    \n",
    "    #----------------------DATA LOADING------------------------------#\n",
    "    \n",
    "    x_train, y_train = np.load(path + 'x_train.npy'), np.load(path + 'y_train.npy')\n",
    "    x_test, y_test = np.load(path + 'x_test.npy'), np.load(path + 'y_test.npy')\n",
    "    x_val, y_val = np.load(path + 'x_val.npy'), np.load(path + 'y_val.npy')\n",
    "\n",
    "    # BAG_TEST, BAG_TRAIN, BAG_VAL represent bag_level labels. These are used for the label update\n",
    "    # step of EMI/MI RNN\n",
    "    BAG_TEST = np.argmax(y_test[:, 0, :], axis=1)\n",
    "    BAG_TRAIN = np.argmax(y_train[:, 0, :], axis=1)\n",
    "    BAG_VAL = np.argmax(y_val[:, 0, :], axis=1)\n",
    "    NUM_SUBINSTANCE = x_train.shape[1]\n",
    "    print(\"x_train shape is:\", x_train.shape)\n",
    "    print(\"y_train shape is:\", y_train.shape)\n",
    "    print(\"x_test shape is:\", x_val.shape)\n",
    "    print(\"y_test shape is:\", y_val.shape)\n",
    "    \n",
    "    #----------------------END OF DATA LOADING------------------------------#    \n",
    "    \n",
    "    #----------------------COMPUTATION GRAPH--------------------------------#\n",
    "    \n",
    "    # Define the linear secondary classifier\n",
    "    def createExtendedGraph(self, baseOutput, *args, **kwargs):\n",
    "        W1 = tf.Variable(np.random.normal(size=[NUM_HIDDEN, NUM_OUTPUT]).astype('float32'), name='W1')\n",
    "        B1 = tf.Variable(np.random.normal(size=[NUM_OUTPUT]).astype('float32'), name='B1')\n",
    "        y_cap = tf.add(tf.tensordot(baseOutput, W1, axes=1), B1, name='y_cap_tata')\n",
    "        self.output = y_cap\n",
    "        self.graphCreated = True\n",
    "\n",
    "    def restoreExtendedGraph(self, graph, *args, **kwargs):\n",
    "        y_cap = graph.get_tensor_by_name('y_cap_tata:0')\n",
    "        self.output = y_cap\n",
    "        self.graphCreated = True\n",
    "\n",
    "    def feedDictFunc(self, keep_prob=None, inference=False, **kwargs):\n",
    "        if inference is False:\n",
    "            feedDict = {self._emiGraph.keep_prob: keep_prob}\n",
    "        else:\n",
    "            feedDict = {self._emiGraph.keep_prob: 1.0}\n",
    "        return feedDict\n",
    "\n",
    "    EMI_BasicLSTM._createExtendedGraph = createExtendedGraph\n",
    "    EMI_BasicLSTM._restoreExtendedGraph = restoreExtendedGraph\n",
    "\n",
    "    if USE_DROPOUT is True:\n",
    "        EMI_Driver.feedDictFunc = feedDictFunc\n",
    "    \n",
    "    inputPipeline = EMI_DataPipeline(NUM_SUBINSTANCE, NUM_TIMESTEPS, NUM_FEATS, NUM_OUTPUT)\n",
    "    emiLSTM = EMI_BasicLSTM(NUM_SUBINSTANCE, NUM_HIDDEN, NUM_TIMESTEPS, NUM_FEATS,\n",
    "                            forgetBias=FORGET_BIAS, useDropout=USE_DROPOUT)\n",
    "    emiTrainer = EMI_Trainer(NUM_TIMESTEPS, NUM_OUTPUT, lossType='xentropy',\n",
    "                             stepSize=LEARNING_RATE)\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    g1 = tf.Graph()    \n",
    "    with g1.as_default():\n",
    "        # Obtain the iterators to each batch of the data\n",
    "        x_batch, y_batch = inputPipeline()\n",
    "        # Create the forward computation graph based on the iterators\n",
    "        y_cap = emiLSTM(x_batch)\n",
    "        # Create loss graphs and training routines\n",
    "        emiTrainer(y_cap, y_batch)\n",
    "        \n",
    "    #------------------------------END OF COMPUTATION GRAPH------------------------------#\n",
    "    \n",
    "    #-------------------------------------EMI DRIVER-------------------------------------#\n",
    "        \n",
    "    with g1.as_default():\n",
    "        emiDriver = EMI_Driver(inputPipeline, emiLSTM, emiTrainer)\n",
    "\n",
    "    emiDriver.initializeSession(g1)\n",
    "    y_updated, modelStats = emiDriver.run(numClasses=NUM_OUTPUT, x_train=x_train,\n",
    "                                          y_train=y_train, bag_train=BAG_TRAIN,\n",
    "                                          x_val=x_val, y_val=y_val, bag_val=BAG_VAL,\n",
    "                                          numIter=NUM_ITER, keep_prob=KEEP_PROB,\n",
    "                                          numRounds=NUM_ROUNDS, batchSize=BATCH_SIZE,\n",
    "                                          numEpochs=NUM_EPOCHS, modelPrefix=MODEL_PREFIX,\n",
    "                                          fracEMI=0.5, updatePolicy='top-k', k=1)\n",
    "    \n",
    "    #-------------------------------END OF EMI DRIVER-------------------------------------#\n",
    "    \n",
    "    #-----------------------------------EARLY SAVINGS-------------------------------------#\n",
    "    \n",
    "    \"\"\"\n",
    "        Early Prediction Policy: We make an early prediction based on the predicted classes\n",
    "        probability. If the predicted class probability > minProb at some step, we make\n",
    "        a prediction at that step.\n",
    "    \"\"\"\n",
    "    def earlyPolicy_minProb(instanceOut, minProb, **kwargs):\n",
    "        assert instanceOut.ndim == 2\n",
    "        classes = np.argmax(instanceOut, axis=1)\n",
    "        prob = np.max(instanceOut, axis=1)\n",
    "        index = np.where(prob >= minProb)[0]\n",
    "        if len(index) == 0:\n",
    "            assert (len(instanceOut) - 1) == (len(classes) - 1)\n",
    "            return classes[-1], len(instanceOut) - 1\n",
    "        index = index[0]\n",
    "        return classes[index], index\n",
    "\n",
    "    def getEarlySaving(predictionStep, numTimeSteps, returnTotal=False):\n",
    "        predictionStep = predictionStep + 1\n",
    "        predictionStep = np.reshape(predictionStep, -1)\n",
    "        totalSteps = np.sum(predictionStep)\n",
    "        maxSteps = len(predictionStep) * numTimeSteps\n",
    "        savings = 1.0 - (totalSteps / maxSteps)\n",
    "        if returnTotal:\n",
    "            return savings, totalSteps\n",
    "        return savings\n",
    "    \n",
    "    #--------------------------------END OF EARLY SAVINGS---------------------------------#\n",
    "    \n",
    "    #----------------------------------------BEST MODEL-----------------------------------#\n",
    "    \n",
    "    k = 2\n",
    "    predictions, predictionStep = emiDriver.getInstancePredictions(x_test, y_test, earlyPolicy_minProb,\n",
    "                                                                   minProb=0.99, keep_prob=1.0)\n",
    "    bagPredictions = emiDriver.getBagPredictions(predictions, minSubsequenceLen=k, numClass=NUM_OUTPUT)\n",
    "    print('Accuracy at k = %d: %f' % (k,  np.mean((bagPredictions == BAG_TEST).astype(int))))\n",
    "    mi_savings = (1 - NUM_TIMESTEPS / ORIGINAL_NUM_TIMESTEPS)\n",
    "    emi_savings = getEarlySaving(predictionStep, NUM_TIMESTEPS)\n",
    "    total_savings = mi_savings + (1 - mi_savings) * emi_savings\n",
    "    print('Savings due to MI-RNN : %f' % mi_savings)\n",
    "    print('Savings due to Early prediction: %f' % emi_savings)\n",
    "    print('Total Savings: %f' % (total_savings))\n",
    "    \n",
    "    #Store in the dictionary.\n",
    "    lstm_dict[\"k\"] = k\n",
    "    lstm_dict[\"accuracy\"] = np.mean((bagPredictions == BAG_TEST).astype(int))\n",
    "    lstm_dict[\"total_savings\"] = total_savings\n",
    "    lstm_dict[\"y_test\"] = BAG_TEST\n",
    "    lstm_dict[\"y_pred\"] = bagPredictions\n",
    "    \n",
    "    # A slightly more detailed analysis method is provided. \n",
    "    df = emiDriver.analyseModel(predictions, BAG_TEST, NUM_SUBINSTANCE, NUM_OUTPUT)\n",
    "#     print (tabulate(df, headers=list(df.columns), tablefmt='grid'))\n",
    "    \n",
    "    lstm_dict[\"detailed analysis\"] = df\n",
    "    #----------------------------------END OF BEST MODEL-----------------------------------#\n",
    "    \n",
    "    #----------------------------------PICKING THE BEST MODEL------------------------------#\n",
    "    \n",
    "    devnull = open(os.devnull, 'r')\n",
    "    for val in modelStats:\n",
    "        round_, acc, modelPrefix, globalStep = val\n",
    "        emiDriver.loadSavedGraphToNewSession(modelPrefix, globalStep, redirFile=devnull)\n",
    "        predictions, predictionStep = emiDriver.getInstancePredictions(x_test, y_test, earlyPolicy_minProb,\n",
    "                                                                   minProb=0.99, keep_prob=1.0)\n",
    "\n",
    "        bagPredictions = emiDriver.getBagPredictions(predictions, minSubsequenceLen=k, numClass=NUM_OUTPUT)\n",
    "        print(\"Round: %2d, Validation accuracy: %.4f\" % (round_, acc), end='')\n",
    "        print(', Test Accuracy (k = %d): %f, ' % (k,  np.mean((bagPredictions == BAG_TEST).astype(int))), end='')\n",
    "        print('Additional savings: %f' % getEarlySaving(predictionStep, NUM_TIMESTEPS)) \n",
    "        \n",
    "    \n",
    "    #-------------------------------END OF PICKING THE BEST MODEL--------------------------#\n",
    "\n",
    "    return lstm_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline EMI-LSTM.\n",
    "\n",
    "dataset = 'peliculas'\n",
    "path = '/home/adithyapa4444_gmail_com/6_2/'\n",
    "\n",
    "#Choose model from among [lstm, fastgrnn, gru]\n",
    "model = 'lstm'\n",
    "\n",
    "# Dictionary to set the parameters.\n",
    "params = {\n",
    "    \"NUM_HIDDEN\" : 128,\n",
    "    \"NUM_TIMESTEPS\" : 6, #subinstance length.\n",
    "    \"ORIGINAL_NUM_TIMESTEPS\" :12, # Window length \n",
    "    \"NUM_FEATS\" : 540,\n",
    "    \"FORGET_BIAS\" : 1.0,\n",
    "    \"NUM_OUTPUT\" : 2,   # Number of target classes\n",
    "    \"USE_DROPOUT\" : 1, # '1' -> True. '0' -> False\n",
    "    \"KEEP_PROB\" : 0.75,\n",
    "    \"PREFETCH_NUM\" : 5,\n",
    "    \"BATCH_SIZE\" : 32,\n",
    "    \"NUM_EPOCHS\" : 10,\n",
    "    \"NUM_ITER\" : 4,\n",
    "    \"NUM_ROUNDS\" : 10,\n",
    "    \"LEARNING_RATE\" : 0.001,\n",
    "    \"MODEL_PREFIX\" : dataset + '/model-' + str(model)\n",
    "}\n",
    "import os,datetime\n",
    "\n",
    "#Preprocess data, and load the train,test and validation splits.\n",
    "#lstm_dict = experiment_generator(params, path, model)\n",
    "lstm_dict = lstm_experiment_generator(params, path)\n",
    "#Create the directory to store the results of this run.\n",
    "\n",
    "dirname = \"\"\n",
    "dirname = \"./Results\" + ''.join(dirname) + \"/\"+dataset+\"/\"+model\n",
    "pathlib.Path(dirname).mkdir(parents=True, exist_ok=True)\n",
    "print (\"Results for this run have been saved at\" , dirname, \".\")\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "filename = list((str(now.year),\"-\",str(now.month),\"-\",str(now.day),\"|\",str(now.hour),\"-\",str(now.minute)))\n",
    "filename = ''.join(filename)\n",
    "\n",
    "#Save the dictionary containing the params and the results.\n",
    "import pickle as pkl\n",
    "pkl.dump(lstm_dict,open(dirname + \"/lstm_dict_\" + filename + \".pkl\",mode='wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-19T11:47:35.694831Z",
     "start_time": "2018-08-19T11:47:35.592516Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "path = '/home/adithyapa4444_gmail_com/6_2/'\n",
    "x_train, y_train = np.load(path +'x_train.npy'), np.load(path +'y_train.npy')\n",
    "x_test, y_test = np.load(path +'x_test.npy'), np.load(path +'y_test.npy')\n",
    "x_val, y_val = np.load(path +'x_val.npy'), np.load(path +'y_val.npy')\n",
    "\n",
    "# BAG_TEST, BAG_TRAIN, BAG_VAL represent bag_level labels. These are used for the label update\n",
    "# step of EMI/MI RNN\n",
    "BAG_TEST = np.argmax(y_test[:, 0, :], axis=1)\n",
    "BAG_TRAIN = np.argmax(y_train[:, 0, :], axis=1)\n",
    "BAG_VAL = np.argmax(y_val[:, 0, :], axis=1)\n",
    "NUM_SUBINSTANCE = x_train.shape[1]\n",
    "print(\"x_train shape is:\", x_train.shape)\n",
    "print(\"y_train shape is:\", y_train.shape)\n",
    "print(\"x_test shape is:\", x_val.shape)\n",
    "print(\"y_test shape is:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-19T11:47:35.739003Z",
     "start_time": "2018-08-19T11:47:35.696723Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the linear secondary classifier\n",
    "def createExtendedGraph(self, baseOutput, *args, **kwargs):\n",
    "    W1 = tf.Variable(np.random.normal(size=[NUM_HIDDEN, NUM_OUTPUT]).astype('float32'), name='W1')\n",
    "    B1 = tf.Variable(np.random.normal(size=[NUM_OUTPUT]).astype('float32'), name='B1')\n",
    "    y_cap = tf.add(tf.tensordot(baseOutput, W1, axes=1), B1, name='y_cap_tata')\n",
    "    self.output = y_cap\n",
    "    self.graphCreated = True\n",
    "    \n",
    "def addExtendedAssignOps(self, graph, W_val=None, B_val=None):\n",
    "    W1 = graph.get_tensor_by_name('W1:0')\n",
    "    B1 = graph.get_tensor_by_name('B1:0')\n",
    "    W1_op = tf.assign(W1, W_val)\n",
    "    B1_op = tf.assign(B1, B_val)\n",
    "    self.assignOps.extend([W1_op, B1_op])\n",
    "\n",
    "def restoreExtendedGraph(self, graph, *args, **kwargs):\n",
    "    y_cap = graph.get_tensor_by_name('y_cap_tata:0')\n",
    "    self.output = y_cap\n",
    "    self.graphCreated = True\n",
    "    \n",
    "def feedDictFunc(self, keep_prob, **kwargs):\n",
    "    feedDict = {self._emiGraph.keep_prob: keep_prob}\n",
    "    return feedDict\n",
    "    \n",
    "EMI_GRU._createExtendedGraph = createExtendedGraph\n",
    "EMI_GRU._restoreExtendedGraph = restoreExtendedGraph\n",
    "EMI_GRU.addExtendedAssignOps = addExtendedAssignOps\n",
    "\n",
    "if USE_DROPOUT is True:\n",
    "    EMI_Driver.feedDictFunc = feedDictFunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-19T11:48:33.294431Z",
     "start_time": "2018-08-19T11:48:32.897376Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def earlyPolicy_minProb(instanceOut, minProb, **kwargs):\n",
    "    assert instanceOut.ndim == 2\n",
    "    classes = np.argmax(instanceOut, axis=1)\n",
    "    prob = np.max(instanceOut, axis=1)\n",
    "    index = np.where(prob >= minProb)[0]\n",
    "    if len(index) == 0:\n",
    "        assert (len(instanceOut) - 1) == (len(classes) - 1)\n",
    "        return classes[-1], len(instanceOut) - 1\n",
    "    index = index[0]\n",
    "    return classes[index], index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-19T09:34:06.288012Z",
     "start_time": "2018-08-19T09:34:06.285286Z"
    }
   },
   "source": [
    "## 1. Initializing a New Computation Graph\n",
    "\n",
    "In the most common use cases, a new EMI-RNN graph would be created and trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-19T11:49:55.326002Z",
     "start_time": "2018-08-19T11:49:50.568621Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "inputPipeline = EMI_DataPipeline(NUM_SUBINSTANCE, NUM_TIMESTEPS, NUM_FEATS, NUM_OUTPUT)\n",
    "emiGRU = EMI_BasicLSTM(NUM_SUBINSTANCE, NUM_HIDDEN, NUM_TIMESTEPS, NUM_FEATS,\n",
    "                        useDropout=USE_DROPOUT)\n",
    "emiTrainer = EMI_Trainer(NUM_TIMESTEPS, NUM_OUTPUT, lossType='xentropy')\n",
    "\n",
    "# Construct the graph\n",
    "g1 = tf.Graph()    \n",
    "with g1.as_default():\n",
    "    x_batch, y_batch = inputPipeline()\n",
    "    y_cap = emiGRU(x_batch)\n",
    "    emiTrainer(y_cap, y_batch)\n",
    "    \n",
    "with g1.as_default():\n",
    "    emiDriver = EMI_Driver(inputPipeline, emiGRU, emiTrainer)\n",
    "\n",
    "emiDriver.initializeSession(g1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets initialize a new session with this graph and train a model. The saved model will be used later for restoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-19T11:48:32.894784Z",
     "start_time": "2018-08-19T11:47:41.258027Z"
    }
   },
   "outputs": [],
   "source": [
    "# emiDriver.initializeSession(g1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-19T11:48:32.894784Z",
     "start_time": "2018-08-19T11:47:41.258027Z"
    }
   },
   "outputs": [],
   "source": [
    "# y_updated, modelStats = emiDriver.run(numClasses=NUM_OUTPUT, x_train=x_train,\n",
    "#                                       y_train=y_train, bag_train=BAG_TRAIN,\n",
    "#                                       x_val=x_val, y_val=y_val, bag_val=BAG_VAL,\n",
    "#                                       numIter=NUM_ITER, keep_prob=KEEP_PROB,\n",
    "#                                       numRounds=NUM_ROUNDS, batchSize=BATCH_SIZE,\n",
    "#                                       numEpochs=NUM_EPOCHS, modelPrefix=MODEL_PREFIX,\n",
    "#                                       fracEMI=0.5, updatePolicy='top-k', k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the output above indicates, the last restored model is `/tmp/model-lstm-1001`. That is, with `MODEL_PREFIX = '/tmp/model-lstm'` and `GLOBAL_STEP=1001`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-19T11:48:33.294431Z",
     "start_time": "2018-08-19T11:48:32.897376Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "k = 2\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "predictions, predictionStep = emiDriver.getInstancePredictions(x_test, y_test, earlyPolicy_minProb,\n",
    "                                                               minProb=0.99, keep_prob=1.0)\n",
    "bagPredictions = emiDriver.getBagPredictions(predictions, minSubsequenceLen=k, numClass=NUM_OUTPUT)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-19T11:48:33.294431Z",
     "start_time": "2018-08-19T11:48:32.897376Z"
    }
   },
   "outputs": [],
   "source": [
    "# print('Accuracy at k = %d: %f' % (k,  np.mean((bagPredictions == BAG_TEST).astype(int))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading a Saved Graph into EMI-Driver\n",
    "\n",
    "We will reset the computation graph, load a saved graph into the current `EMI_Driver` and verify its outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-19T11:48:38.811810Z",
     "start_time": "2018-08-19T11:48:33.296990Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "emiDriver.loadSavedGraphToNewSession(MODEL_PREFIX, 1030)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PREFIX.split('-')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-19T11:48:38.811810Z",
     "start_time": "2018-08-19T11:48:33.296990Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "k = 2\n",
    "predictions, predictionStep = emiDriver.getInstancePredictions(x_test, y_test, earlyPolicy_minProb,\n",
    "                                                               minProb=0.99, keep_prob=1.0)\n",
    "bagPredictions = emiDriver.getBagPredictions(predictions, minSubsequenceLen=k, numClass=NUM_OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-19T11:48:38.811810Z",
     "start_time": "2018-08-19T11:48:33.296990Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Accuracy at k = %d: %f' % (k,  np.mean((bagPredictions == BAG_TEST).astype(int))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------- END------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initializing using a Saved Graph\n",
    "\n",
    "Here we will construct a new computation graph, but will use a previously trained model to initialize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-19T11:48:38.818037Z",
     "start_time": "2018-08-19T11:48:38.814131Z"
    }
   },
   "outputs": [],
   "source": [
    "# Making sure the old graph and sessions are closed\n",
    "sess = emiDriver.getCurrentSession()\n",
    "sess.close()\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `GraphManager` to load the saved graph and load it into a new session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-19T11:48:43.329691Z",
     "start_time": "2018-08-19T11:48:38.819945Z"
    }
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "graphManager = edgeml.utils.GraphManager()\n",
    "graph = graphManager.loadCheckpoint(sess, MODEL_PREFIX, globalStep=1004)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the forward graph as before, but provide the loaded `graph` as an argument to `__init__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-19T11:48:43.410591Z",
     "start_time": "2018-08-19T11:48:43.337841Z"
    }
   },
   "outputs": [],
   "source": [
    "inputPipeline = EMI_DataPipeline(NUM_SUBINSTANCE, NUM_TIMESTEPS, NUM_FEATS, NUM_OUTPUT, graph=graph)\n",
    "emiLSTM = EMI_BasicLSTM(NUM_SUBINSTANCE, NUM_HIDDEN, NUM_TIMESTEPS, NUM_FEATS,\n",
    "                        forgetBias=FORGET_BIAS, useDropout=USE_DROPOUT, graph=graph)\n",
    "emiTrainer = EMI_Trainer(NUM_TIMESTEPS, NUM_OUTPUT, lossType='xentropy', graph=graph)\n",
    "\n",
    "g1 = graph\n",
    "with g1.as_default():\n",
    "    x_batch, y_batch = inputPipeline()\n",
    "    y_cap = emiLSTM(x_batch)\n",
    "    emiTrainer(y_cap, y_batch)\n",
    "    \n",
    "with g1.as_default():\n",
    "    emiDriver = EMI_Driver(inputPipeline, emiLSTM, emiTrainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let `EMI_Driver` know that we already have a session in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-19T11:48:43.424410Z",
     "start_time": "2018-08-19T11:48:43.421920Z"
    }
   },
   "outputs": [],
   "source": [
    "emiDriver.setSession(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-19T11:48:44.324735Z",
     "start_time": "2018-08-19T11:48:43.426174Z"
    }
   },
   "outputs": [],
   "source": [
    "k = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-19T11:48:44.324735Z",
     "start_time": "2018-08-19T11:48:43.426174Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "predictions, predictionStep = emiDriver.getInstancePredictions(x_test, y_test, earlyPolicy_minProb,\n",
    "                                                               minProb=0.99, keep_prob=1.0)\n",
    "start = time.time()\n",
    "bagPredictions = emiDriver.getBagPredictions(predictions, minSubsequenceLen=k, numClass=NUM_OUTPUT)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-19T11:48:44.324735Z",
     "start_time": "2018-08-19T11:48:43.426174Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Accuracy at k = %d: %f' % (k,  np.mean((bagPredictions == BAG_TEST).astype(int))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Restoring from Numpy Matrices\n",
    "\n",
    "We first extract the model matrices from the graph and dump it into `.npy` files. Then we load it back again and initialize a new graph with these matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-19T11:48:44.379901Z",
     "start_time": "2018-08-19T11:48:44.326706Z"
    }
   },
   "outputs": [],
   "source": [
    "graph = tf.get_default_graph()\n",
    "W1 = graph.get_tensor_by_name('W1:0')\n",
    "B1 = graph.get_tensor_by_name('B1:0')\n",
    "allVars = emiLSTM.varList + [W1, B1]\n",
    "sess = emiDriver.getCurrentSession()\n",
    "allVars = sess.run(allVars)\n",
    "\n",
    "base = '/tmp/models/'\n",
    "np.save(base + 'kernel.npy', allVars[0])\n",
    "np.save(base + 'bias.npy', allVars[1])\n",
    "np.save(base + 'W1.npy', allVars[2])\n",
    "np.save(base + 'B1.npy', allVars[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-19T11:16:55.606967Z",
     "start_time": "2018-08-19T11:16:55.535964Z"
    }
   },
   "source": [
    "Reset the current session and graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-19T11:48:44.389724Z",
     "start_time": "2018-08-19T11:48:44.381802Z"
    }
   },
   "outputs": [],
   "source": [
    "sess = emiDriver.getCurrentSession()\n",
    "sess.close()\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the numpy matrices that will be used to initialize the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-19T11:48:44.442241Z",
     "start_time": "2018-08-19T11:48:44.391384Z"
    }
   },
   "outputs": [],
   "source": [
    "base = '/tmp/models/'\n",
    "kernel = np.load(base + 'kernel.npy')\n",
    "bias = np.load(base + 'bias.npy')\n",
    "W = np.load(base + 'W1.npy')\n",
    "B = np.load(base + 'B1.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-19T11:38:36.118298Z",
     "start_time": "2018-08-19T11:38:36.113810Z"
    }
   },
   "source": [
    "Proceed with graph construction as normally done, except that we add the requisite assignment operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-19T11:48:51.378377Z",
     "start_time": "2018-08-19T11:48:44.444182Z"
    }
   },
   "outputs": [],
   "source": [
    "inputPipeline = EMI_DataPipeline(NUM_SUBINSTANCE, NUM_TIMESTEPS, NUM_FEATS,\n",
    "                                 NUM_OUTPUT)\n",
    "emiLSTM = EMI_BasicLSTM(NUM_SUBINSTANCE, NUM_HIDDEN, NUM_TIMESTEPS, NUM_FEATS,\n",
    "                        forgetBias=FORGET_BIAS, useDropout=USE_DROPOUT)\n",
    "emiTrainer = EMI_Trainer(NUM_TIMESTEPS, NUM_OUTPUT, lossType='xentropy')\n",
    "\n",
    "tf.reset_default_graph()\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    x_batch, y_batch = inputPipeline()\n",
    "    y_cap = emiLSTM(x_batch)\n",
    "    emiTrainer(y_cap, y_batch)\n",
    "    # Add the assignment operations\n",
    "    emiLSTM.addBaseAssignOps(graph, [kernel, bias])\n",
    "    emiLSTM.addExtendedAssignOps(graph, W, B)\n",
    "    # Setup the driver. You can run the initializations manually as well\n",
    "    emiDriver = EMI_Driver(inputPipeline, emiLSTM, emiTrainer)\n",
    "\n",
    "emiDriver.initializeSession(graph)\n",
    "# Run the assignment operations\n",
    "sess = emiDriver.getCurrentSession()\n",
    "sess.run(emiLSTM.assignOps)\n",
    "\n",
    "k = 2\n",
    "predictions, predictionStep = emiDriver.getInstancePredictions(x_test, y_test,\n",
    "                                                               earlyPolicy_minProb,\n",
    "                                                               minProb=0.99,\n",
    "                                                               keep_prob=1.0)\n",
    "bagPredictions = emiDriver.getBagPredictions(predictions, minSubsequenceLen=k,\n",
    "                                             numClass=NUM_OUTPUT)\n",
    "print('PART IV: Accuracy at k = %d: %f' % (k,  np.mean((bagPredictions ==\n",
    "                                                        BAG_TEST).astype(int))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
